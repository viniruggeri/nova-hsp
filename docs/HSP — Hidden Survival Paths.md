HSP â€” Hidden Survival Paths

1\. Ideia central

O HSP Ã© um framework para detectar colapso sistÃªmico antes de sinais observÃ¡veis, medindo nÃ£o o estado atual do sistema, mas a existÃªncia de futuros viÃ¡veis.

SobrevivÃªncia â‰  ainda nÃ£o falhou  
SobrevivÃªncia \= existem trajetÃ³rias futuras possÃ­veis a partir do estado atual.

Quando esse conjunto de trajetÃ³rias colapsa, o sistema jÃ¡ estÃ¡ extinto â€” mesmo que mÃ©tricas tradicionais ainda pareÃ§am estÃ¡veis.

\---

2\. FormulaÃ§Ã£o conceitual

Considere um sistema dinÃ¢mico com estado latente .

A partir de , amostramos mÃºltiplas trajetÃ³rias futuras .

Definimos uma funÃ§Ã£o de viabilidade:

trajetÃ³rias que respeitam restriÃ§Ãµes fÃ­sicas / ecolÃ³gicas / estruturais sobrevivem

trajetÃ³rias inviÃ¡veis sÃ£o descartadas

O HSP estima:

\> 

A queda persistente de  indica colapso iminente.

\---

3\. Arquitetura geral

3.1 Pipeline

1\. ObservaÃ§Ã£o do estado atual

2\. Amostragem de futuros possÃ­veis (simulaÃ§Ã£o / modelo generativo)

3\. ConstruÃ§Ã£o de um grafo de futuros:

nÃ³s \= estados futuros

arestas \= transiÃ§Ãµes viÃ¡veis

4\. AgregaÃ§Ã£o estrutural via GNN

5\. CÃ¡lculo do score HSP (densidade, conectividade, entropia)

6\. DetecÃ§Ã£o de colapso por regra simples (nÃ£o supervisionada)

\---

4\. Modelos envolvidos

SimulaÃ§Ã£o / Mundo artificial

ABM (ex: formigueiro, epidemia em grafo)

RepresentaÃ§Ã£o

PyTorch Geometric (GNNs leves)

Graph-level pooling

Modelos auxiliares

LSTM / NSSM simples para gerar trajetÃ³rias

Nenhum classificador supervisionado

\---

5\. MÃ©tricas principais

Lead Time (principal)

quanto antes o HSP alerta em relaÃ§Ã£o ao evento real

RMSE / erro de reconstruÃ§Ã£o (auxiliar)

Estabilidade temporal do score

Baselines de comparaÃ§Ã£o

LSTM de previsÃ£o direta

Transformer temporal

DetecÃ§Ã£o de drift estatÃ­stico

\---

6\. Mundos de teste (PoC)

6.1 Epidemia em grafo

Casos aparentam estabilidade

Conectividade futura colapsa

6.2 ABM de colÃ´nia (formigas)

RefÃºgios locais

ExtinÃ§Ã£o global inevitÃ¡vel

Objetivo: mostrar que o HSP alerta antes de qualquer mÃ©trica clÃ¡ssica.

\---

7\. Stack tÃ©cnica (enxuta)

Python

PyTorch \+ PyTorch Geometric

NumPy / SciPy / math

Pandas \+ Great Expectations

Matplotlib / Seaborn

MLOps

MLflow

Hydra

DVC

pre-commit

Arize AI

\---

8\. RestriÃ§Ãµes prÃ¡ticas

Hardware limitado (8GB RAM)

Prioridade total em provar a ideia, nÃ£o escalar

Amostras pequenas, mundos controlados

\---

9\. Papel do Patrick

ConstruÃ§Ã£o dos mundos artificiais

DefiniÃ§Ã£o das regras dinÃ¢micas

Garantir que o colapso Ã© estrutural (nÃ£o bug)

Sanity checks matemÃ¡ticos

O HSP observa. O mundo precisa ser correto.

\---

10\. Frase-resumo

\> Baselines olham o presente.  
O HSP mede se ainda existe futuro.

\---

Outline de Paper (Draft)

TÃ­tulo (provisÃ³rio)

Hidden Survival Paths: Early Detection of Latent Extinction via Future Reachability Collapse

Abstract

Propomos o Hidden Survival Paths (HSP), um framework nÃ£o supervisionado para detecÃ§Ã£o precoce de extinÃ§Ã£o latente em sistemas dinÃ¢micos. Diferentemente de abordagens supervisionadas que dependem de colapso observÃ¡vel, o HSP define extinÃ§Ã£o como perda de alcanÃ§abilidade futura no espaÃ§o de estados. Demonstramos, em mundos simulados com epidemias em grafos e agentes com refÃºgios, que o HSP detecta colapso estrutural com maior lead time sob observaÃ§Ãµes parciais, superando LSTM, Transformer temporal e detectores de drift.

1\. IntroduÃ§Ã£o

LimitaÃ§Ãµes de mÃ©todos supervisionados baseados em observÃ¡veis

ExtinÃ§Ã£o como propriedade dinÃ¢mica/topolÃ³gica

ContribuiÃ§Ãµes principais

2\. DefiniÃ§Ã£o do Problema

Sistema dinÃ¢mico desconhecido

ObservaÃ§Ãµes parciais

Objetivo: detectar perda de futuros viÃ¡veis antes do colapso observÃ¡vel

3\. Hidden Survival Paths

Amostragem de futuros

ConstruÃ§Ã£o de grafo implÃ­cito de transiÃ§Ãµes

MÃ©trica de opcionalidade futura

CritÃ©rio de alerta

4\. Mundos Simulados

Epidemia em grafos (BA, modular)

ABM com refÃºgios (formigas ou Fallout-lite)

5\. Baselines

LSTM forecasting \+ threshold

Temporal Transformer (light)

Detector de drift (CUSUM / ADWIN)

6\. MÃ©tricas

Lead Time (principal)

RMSE (secundÃ¡ria, contextual)

FPR e robustez sob ruÃ­do

7\. Resultados

Curvas de opcionalidade vs observÃ¡veis

Tabela de lead time

AnÃ¡lise contrafactual

8\. DiscussÃ£o

Falhas estruturais dos baselines

ImplicaÃ§Ãµes para detecÃ§Ã£o precoce

9\. ConclusÃ£o

ExtinÃ§Ã£o latente Ã© detectÃ¡vel sem rÃ³tulos

HSP como ferramenta cientÃ­fica

**NÃšCLEO MATEMÃTICO**  
\\\\section{NÃºcleo MatemÃ¡tico}

\\paragraph{Sistema.}  
Seja $(\\mathcal{Z},\\mathcal{B})$ um espaÃ§o de estados mensurÃ¡vel.  
O sistema evolui como um processo estocÃ¡stico possivelmente nÃ£o-Markoviano  
\\\[  
z\_{t+1}\\sim\\mathcal{P}(\\cdot\\mid z\_t,\\Theta),  
\\\]  
onde \\(\\Theta\\) denota parÃ¢metros latentes, potencialmente nÃ£o  
identificÃ¡veis, e \\(\\mathcal{P}\\) pode estar mal-especificado.

\\paragraph{DomÃ­nio de SobrevivÃªncia.}  
Denotemos por \\(\\mathcal{S}\\subset\\mathcal{Z}\\) o conjunto de estados  
viÃ¡veis. NÃ£o assumimos que \\(\\mathcal{S}\\) seja totalmente observÃ¡vel.

\\paragraph{TrajetÃ³rias Futuras.}  
Para um horizonte \\(T\\in\\mathbb{N}\\) e estado atual \\(z\_t\\in\\mathcal{Z}\\),  
seja \\(\\mathbb{P}\_{\\Gamma}(\\cdot\\mid z\_t)\\) a medida de probabilidade  
induzida sobre trajetÃ³rias de comprimento \\(T\\)  
\\\[  
\\gamma=(z\_t,z\_{t+1},\\dots,z\_{t+T}),  
\\\]  
obtida ao amostrar parÃ¢metros latentes \\(\\Theta\\) e ruÃ­do do sistema.  
NÃ£o assumimos que \\(\\mathbb{P}\_{\\Gamma}\\) seja o processo gerador  
verdadeiro, apenas que gera futuros localmente plausÃ­veis.

\\paragraph{Hidden Survival Path (HSP).}  
Dado \\(\\tau\\in(0,1)\\), uma trajetÃ³ria  
\\(\\gamma\\sim\\mathbb{P}\_{\\Gamma}(\\cdot\\mid z\_t)\\) Ã© uma  
\\emph{Hidden Survival Path (HSP)} se  
\\\[  
\\mathbb{P}\\\!\\left(z\_{t+k}\\in\\mathcal{S},\\;\\forall k\\le T \\mid z\_t\\right)  
\\ge\\tau.  
\\\]  
Esta definiÃ§Ã£o trata sobrevivÃªncia como propriedade de trajetÃ³rias,  
nÃ£o de estados instantÃ¢neos.

\\paragraph{Optionalidade Futura.}  
Definimos a optionalidade futura em \\(t\\) como  
\\\[  
\\mathcal{O}\_T(z\_t)  
:=  
\\mathbb{P}\_{\\gamma\\sim\\mathbb{P}\_{\\Gamma}(\\cdot\\mid z\_t)}  
\\big(\\gamma\\ \\text{Ã© uma HSP}\\big).  
\\\]  
Assim, \\(\\mathcal{O}\_T(z\_t)\\) mede a \\emph{massa} de futuros viÃ¡veis,  
em oposiÃ§Ã£o Ã  mera existÃªncia de uma Ãºnica trajetÃ³ria.

\\paragraph{AproximaÃ§Ã£o por Grafos (epistÃªmica).}  
Seja \\(V\_t\\) uma amostra finita de trajetÃ³rias extraÃ­das de  
\\(\\mathbb{P}\_{\\Gamma}(\\cdot\\mid z\_t)\\). Construa-se o grafo epistemico  
\\(G\_t=(V\_t,E\_t)\\) onde as arestas sÃ£o amostradas por seed de acordo com  
uma similaridade dependente da tarefa:  
\\\[  
\\mathbb{P}\\big\[(v\_i,v\_j)\\in E\_t\\big\] \= \\exp\\\!\\big(-d(v\_i,v\_j)\\big).  
\\\]  
Tratamos \\(G\_t\\) como aproximaÃ§Ã£o epistÃªmica da medida contÃ­nua  
\\(\\mathbb{P}\_{\\Gamma}\\); componentes conectadas em grafos amostrados sÃ£o  
interpretadas como hipÃ³teses sobre regiÃµes mutuamente alcanÃ§Ã¡veis no  
espaÃ§o de futuros.

\\paragraph{Estimador de Optionalidade baseado em Grafo.}  
Para Ã­ndice de amostra \\(m\\), seja  
\\(\\widehat{\\mathcal{O}}\_t^{(m)}\\) a optionalidade empÃ­rica calculada sobre  
componentes conectadas e scores de viabilidade por nÃ³  
\\(s\_i\\in\[0,1\]\\) (ver seÃ§Ã£o de engenharia). A estimativa por ensemble Ã©  
\\\[  
\\widehat{\\mathcal{O}}\_t \= \\mathbb{E}\_m\\big\[\\widehat{\\mathcal{O}}\_t^{(m)}\\big\],  
\\\]  
usada como estimador de Monte Carlo para \\(\\mathcal{O}\_T(z\_t)\\).  
\\textbf{Nota:} \\(s\_i\\) Ã© uma estimativa epistÃªmica de viabilidade  
(baseada no modelo gerador ou em regras), nÃ£o uma probabilidade de  
verdadeiro ground-truth.

\\paragraph{ExtinÃ§Ã£o Latente (persistÃªncia estocÃ¡stica).}  
Dados \\(\\delta,\\eta\\in(0,1)\\) e \\(K\\in\\mathbb{N}\\), declaramos uma  
extinÃ§Ã£o latente persistente em \\(t^\\ast\\) se  
\\\[  
\\mathbb{P}\\\!\\big(\\mathcal{O}\_T(z\_t)\<\\delta\\big) \> \\eta  
\\quad\\text{para todo } t\\in\[t^\\ast,t^\\ast+K\].  
\\\]  
Na prÃ¡tica, \\(\\mathbb{P}(\\mathcal{O}\_T(z\_t)\<\\delta)\\) Ã© estimada pela  
fraÃ§Ã£o de seeds com \\(\\widehat{\\mathcal{O}}\_t^{(m)}\<\\delta\\), e a  
persistÃªncia Ã© avaliada sobre essa estimativa empÃ­rica.

\\paragraph{Lacuna de ObservaÃ§Ã£o.}  
Sejam \\(y\_t=h(z\_t)\\) os sinais observÃ¡veis. Em geral,  
\\\[  
\\mathcal{O}\_T(z\_t)\\downarrow  
\\;\\;\\nRightarrow\\;\\;  
y\_t\\downarrow,  
\\\]  
i.e., observÃ¡veis podem permanecer estÃ¡veis enquanto a massa de futuros  
viÃ¡veis colapsa.

\\paragraph{Tempo de DetecÃ§Ã£o.}  
Definimos o tempo de detecÃ§Ã£o do HSP como  
\\\[  
T\_{\\mathrm{HSP}} := \\inf\\big\\{t:\\; \\mathbb{P}(\\mathcal{O}\_T(z\_t)\<\\delta)\>\\eta\\big\\}.  
\\\]

\\paragraph{AvaliaÃ§Ã£o.}  
Para um baseline supervisionado com tempo de detecÃ§Ã£o  
\\(T\_{\\mathrm{base}}\\), definimos o lead time  
\\(\\Delta T := T\_{\\mathrm{base}} \- T\_{\\mathrm{HSP}}\\).

\\paragraph{Lema de ConvergÃªncia (esboÃ§o).}  
\\textbf{Lema.} Sob condiÃ§Ãµes regulares (boundedness de scores por  
trajetÃ³ria, consistÃªncia do estimador de distÃ¢ncia \\(d\\), e  
\\(|V\_t|\\to\\infty\\)), o estimador de optionalidade baseado em grafos  
converge em probabilidade:  
\\\[  
\\widehat{\\mathcal{O}}\_t \\xrightarrow{p} \\mathcal{O}\_T(z\_t).  
\\\]

\\textbf{EsboÃ§o da prova.} Ã€ medida que \\(|V\_t|\\to\\infty\\), a medida  
empÃ­rica sobre trajetÃ³rias converge fraca\\-mente para  
\\(\\mathbb{P}\_{\\Gamma}(\\cdot\\mid z\_t)\\). Dada a consistÃªncia de \\(d\\),  
a amostragem de arestas induz uma aproximaÃ§Ã£o local consistente da  
conectividade sob a mÃ©trica \\(d\\). A soma por componente de variÃ¡veis  
limitadas \\(s\_i\\) converge, via lei dos grandes nÃºmeros, para a integral  
da massa viÃ¡vel, levando ao resultado.

\\paragraph{CondiÃ§Ãµes de Validade.}  
Um estimador HSP Ã© admissÃ­vel se satisfaz:  
\\begin{enumerate}  
    \\item \\emph{Estabilidade:} \\(\\mathcal{O}\_T\\) Ã© Lipschitz-continua  
    sob pequenas perturbaÃ§Ãµes de \\(\\mathbb{P}\_{\\Gamma}\\).  
    \\item \\emph{Contrafactualidade:} IntervenÃ§Ãµes que aumentam  
    estritamente a alcanÃ§abilidade (reachability) aumentam  
    \\(\\mathcal{O}\_T\\).  
    \\item \\emph{Robustez:} \\(\\mathcal{O}\_T\\) Ã© invariante sob ruÃ­do de  
    observaÃ§Ã£o limitado.  
\\end{enumerate}

\\paragraph{LigaÃ§Ã£o com a construÃ§Ã£o em grafos.}  
A seÃ§Ã£o seguinte desenvolve a construÃ§Ã£o baseada em grafos apresentada  
acima, explicitando o carÃ¡ter epistÃªmico de amostragem por seed e a  
relaÃ§Ã£o operativa entre \\(\\widehat{\\mathcal{O}}\_t\\) e  
\\(\\mathcal{O}\_T(z\_t)\\).

MAPEAMENTO FORMAL

Mapeamento Formal â†’ ImplementaÃ§Ã£o (HSP)

A regra Ã© simples:

\> Nenhum sÃ­mbolo abstrato sem um representante computÃ¡vel claro.

Vou listar em trÃªs camadas:

1\. objetos matemÃ¡ticos

2\. proxy computacional

3\. implementaÃ§Ã£o concreta (PoC-level)

\---

1\. Estado 

DefiniÃ§Ã£o teÃ³rica

z\_t \\in \\mathcal{Z}

Estado completo (latente ou parcialmente observÃ¡vel) do sistema.

Proxy computacional

Embedding vetorial latente:

z\_t \\approx h\_\\phi(x\_t)

onde  sÃ£o observaÃ§Ãµes parciais.

ImplementaÃ§Ã£o

GNN (PyTorch Geometric)

Cada nÃ³ \= agente / regiÃ£o / cÃ©lula

Edge \= contato / mobilidade / troca

Output:

z\_t: Tensor \[num\_nodes, d\]

Sem decoder. Sem autoencoder completo. SÃ³ embedding funcional.

\---

2\. EspaÃ§o de estados 

Teoria

Conjunto implÃ­cito de estados possÃ­veis.

Proxy

Conjunto de embeddings jÃ¡ visitados \+ rollouts futuros.

ImplementaÃ§Ã£o

Buffer leve (NumPy .npy)

Amostragem online

Nada de armazenar tudo (OOM Ã© o inimigo)

\---

3\. DinÃ¢mica 

Teoria

z\_{t+1} \\sim \\mathcal{P}(\\cdot \\mid z\_t)

Desconhecida.

Proxy

Modelo de transiÃ§Ã£o aproximado ou simulador direto.

ImplementaÃ§Ã£o (PoC)

Mundo 1 (SIR): simulador explÃ­cito

Mundo 2 (ABM): regras determinÃ­sticas \+ ruÃ­do

Opcional:

pequeno MLP residual em cima do simulador

sÃ³ se precisar

Nada de treinar dynamics model pesado.

\---

4\. TrajetÃ³rias 

Teoria

Conjunto de futuros possÃ­veis.

Proxy

Ensemble de rollouts estocÃ¡sticos.

ImplementaÃ§Ã£o

for k in range(N\_ensembles):  
    z\_rollout\[k\] \= simulate(z\_t, noise\_k, T)

â€“ jÃ¡ basta

Paraleliza com joblib

Armazena sÃ³ scores, nÃ£o estados completos

\---

5\. Conjunto de sobrevivÃªncia 

Teoria

Estados viÃ¡veis.

Proxy

Score latente de viabilidade:

s(z) \\in \[0,1\]

ImplementaÃ§Ã£o

FunÃ§Ã£o simples, explÃ­cita, auditÃ¡vel:

conectividade mÃ­nima

populaÃ§Ã£o mÃ­nima

recursos \> 0

grau mÃ©dio \> limiar

def survival\_score(z):  
    return float(score \> epsilon)

Sem classificador treinado. Reviewer agradece.

\---

6\. Hidden Survival Path (HSP)

Teoria

TrajetÃ³ria que permanece em  com alta probabilidade.

Proxy

Rollout cuja sequÃªncia de scores nunca zera.

ImplementaÃ§Ã£o

is\_hsp \= all(survival\_score(z\_tk) for t\_k in rollout)

Ou versÃ£o soft:

mean\_score \> tau

\---

7\. Opcionalidade futura 

Teoria

Probabilidade de existir HSP.

Estimador empÃ­rico

\\hat{\\mathcal{O}}\_T(z\_t)  
\=  
\\frac{1}{N}  
\\sum\_{i=1}^N  
\\mathbb{1}\[\\gamma\_i \\text{ Ã© HSP}\]

ImplementaÃ§Ã£o

O\_t \= np.mean(hsp\_flags)

Barato. EstÃ¡vel. InterpretÃ¡vel.

\---

8\. DetecÃ§Ã£o de colapso

Teoria

\\mathcal{O}\_T(z\_t) \< \\delta \\text{ por } K \\text{ passos}

ImplementaÃ§Ã£o

janela deslizante

threshold fixo

if all(O\_t\_window \< delta):  
    alert \= True

Nada de CUSUM aqui. Isso Ã© o sinal HSP, nÃ£o baseline.

\---

9\. Baselines supervisionados

Teoria

Detectam colapso via observÃ¡veis .

ImplementaÃ§Ã£o mÃ­nima

LSTM: forecast \+ threshold

Transformer pequeno

ADWIN / CUSUM

Eles sÃ³ veem:

y\_t \= observable\_metrics(world)

NÃ£o veem grafos latentes. Esse Ã© o ponto.

\---

10\. Lead time 

Teoria

\\Delta T \= T\_{\\text{baseline}} \- T\_{\\text{HSP}}

ImplementaÃ§Ã£o

lead\_time \= t\_baseline \- t\_hsp

Isso Ã© a mÃ©trica-mÃ£e. O resto Ã© decorativo.

\---

11\. Limites de hardware (importante)

NÃ£o guardar rollouts completos

NÃ£o treinar GNN profundo

NÃ£o backprop em tempo longo

NÃ£o usar batch gigante

Tudo:

online

streaming

estatÃ­stico.

ARQUITETURA HSP

Arquitetura HSP, em trÃªs nÃ­veis:

1\. arquitetura canÃ´nica da PoC (o que entra agora, sem OOM, sem loucura)

2\. ideias que entram como hooks opcionais (plugÃ¡veis, nÃ£o centrais)

3\. ideias explicitamente fora da PoC (guardadas para v2/paper futuro)

Assim vocÃª mantÃ©m rigor \+ ambiÃ§Ã£o sem se sabotar.

\---

3/4 â€” Arquitetura do HSP (destilada)

VisÃ£o macro (fluxo)

ObservaÃ§Ãµes / Simulador  
        â†“  
GNN Encoder (estado latente z\_t)  
        â†“  
Sampler de futuros (ensembles)  
        â†“  
AvaliaÃ§Ã£o de sobrevivÃªncia (ğ’®)  
        â†“  
Estimador de opcionalidade ğ’ª\_t  
        â†“  
Detector de colapso \+ lead time

Nada aqui Ã© supÃ©rfluo. Cada bloco existe por necessidade teÃ³rica.

\---

1\. Encoder de estado 

Escolha canÃ´nica (PoC)

GraphSAGE ou GATConv

2â€“3 camadas

hidden dim pequeno (32â€“64)

skip connections âœ”ï¸

Por quÃª

GraphSAGE: estÃ¡vel, barato, inductive

GAT: bom se heterogeneidade/importÃ¢ncia de hubs importa (BA graphs)

Skip connection Ã© importante por um motivo conceitual:

\> nem toda perturbaÃ§Ã£o Ã© colapso (ex.: COVID â‰  extinÃ§Ã£o)

Ela preserva informaÃ§Ã£o prÃ©via quando o sinal novo Ã© ruidoso.

z\_t \= GNN(x\_t, A\_t) \+ z\_{t-1}

\---

AtivaÃ§Ã£o

SiLU ou GELU âœ”ï¸  
EstÃ¡veis, suaves, melhores pra gradientes em sinais fracos.

\---

âŒ Fora da PoC

UNet (overkill)

TGN (temporal graph Ã© lindo, mas pesado)

NSSM completo (guarda pra paper 2\)

\---

2\. DinÃ¢mica temporal (opcional, leve)

Aqui vocÃª tem duas opÃ§Ãµes, ambas vÃ¡lidas.

OpÃ§Ã£o A â€” sem dinÃ¢mica aprendida (default)

usa simulador explÃ­cito

o GNN sÃ³ embeda o estado atual

âœ”ï¸ Mais fiel Ã  teoria  
âœ”ï¸ Mais barato  
âœ”ï¸ Menos risco de leakage

\---

OpÃ§Ã£o B â€” dinÃ¢mica mÃ­nima aprendida

GRU temporal sobre embeddings

hidden pequeno

sem rollout longo

z\_t' \= GRU(z\_t, z\_{t-1})

Usar sÃ³ se:

observaÃ§Ã£o parcial for severa

dinÃ¢mica nÃ£o for totalmente conhecida

\---

âŒ Fora da PoC

NSSM variacional

modelos markovianos profundos

backprop through time longo

\---

3\. Sampling de futuros (nÃºcleo do HSP)

Isso Ã© o coraÃ§Ã£o, nÃ£o o GNN.

ImplementaÃ§Ã£o

Monte Carlo rollouts

ruÃ­do paramÃ©trico \+ estrutural

sem backprop aqui

for i in range(N):  
    future \= simulate(z\_t, noise\_i, T)  
    score\_i \= survival\_score(future)

OtimizaÃ§Ãµes reais

early stopping de rollout se morrer cedo

salvar sÃ³ scores, nunca estados completos

paralelizar CPU (joblib)

\---

4\. SobrevivÃªncia 

Forma canÃ´nica

FunÃ§Ã£o rule-based \+ contÃ­nua:

conectividade do grafo

populaÃ§Ã£o mÃ­nima

diversidade de caminhos

recursos \> 0

Nada supervisionado aqui.

ğ’®(z) \= sigmoid( wâ‚Â·conn \+ wâ‚‚Â·pop \+ wâ‚ƒÂ·paths âˆ’ c )

Isso deixa o gradiente existir sem treinar um classificador.

\---

5\. Opcionalidade futura 

Estimador empÃ­rico, ponto final.

ğ’ª\_t \= (\# rollouts sobreviventes) / N

SuavizaÃ§Ã£o

mÃ©dia mÃ³vel

ReduceLROnPlateau âŒ aqui nÃ£o faz sentido  
(nÃ£o tem loss sendo otimizada)

Mas:

histerese no threshold âœ”ï¸

janela K âœ”ï¸

\---

6\. Detector de colapso

Nada fancy. ElegÃ¢ncia \> complexidade.

if ğ’ª\_t \< Î´ for K steps:  
    alert

Isso Ã© o sinal cientÃ­fico. O resto sÃ£o baselines.

\---

7\. Baselines (onde entram suas ideias)

Aqui sim entram algumas coisas.

Forecasting

LSTM

Transformer pequeno

TCN (ok, barato)

Drift

ADWIN

CUSUM

ECOD / Isolation Forest âœ”ï¸

âŒ SMOTE

NÃ£o faz sentido aqui:

nÃ£o Ã© classificaÃ§Ã£o supervisionada

vai confundir reviewer

\---

8\. RL? Sim, mas nÃ£o agora

RL Ã© vÃ¡lido conceitualmente, mas:

RL entra quando vocÃª age para preservar futuros

a PoC sÃ³ detecta

EntÃ£o:

deixa um stub

uma frase no paper

zero cÃ³digo agora

\---

9\. AtenÃ§Ã£o, ResNet, MLP interno

âœ”ï¸ MLP residual pequeno dentro do GNN  
âœ”ï¸ atenÃ§Ã£o sÃ³ se estruturalmente justificada (GAT jÃ¡ cobre)

Nada de attention genÃ©rica â€œporque simâ€.

\---

10\. O que fica explÃ­cito no paper

VocÃª nÃ£o esconde que isso Ã© modular.

Frase-chave:

\> â€œThe HSP framework is architecture-agnostic; we adopt a minimal GNN encoder to isolate the effect of future reachability.â€

REPO FINAL

Esqueleto do RepositÃ³rio (nova-hsp)

A regra de ouro do repo:

\> rodar inteiro em CPU, GPU sÃ³ acelera ensembles ou GNN se existir

Nada pode quebrar sem CUDA.

\---

Estrutura de pastas (final)

nova-hsp/  
â”‚  
â”œâ”€â”€ README.md  
â”œâ”€â”€ pyproject.toml  
â”œâ”€â”€ requirements.txt  
â”œâ”€â”€ .pre-commit-config.yaml  
â”‚  
â”œâ”€â”€ configs/  
â”‚   â”œâ”€â”€ config.yaml              \# entrypoint Hydra  
â”‚   â”‚  
â”‚   â”œâ”€â”€ hsp/  
â”‚   â”‚   â”œâ”€â”€ base.yaml             \# determinÃ­stico mÃ­nimo  
â”‚   â”‚   â”œâ”€â”€ stochastic.yaml       \# epistemic seeds, graph sampling  
â”‚   â”‚   â”œâ”€â”€ ablation\_no\_gnn.yaml  
â”‚   â”‚   â””â”€â”€ ablation\_no\_sampling.yaml  
â”‚   â”‚  
â”‚   â”œâ”€â”€ worlds/  
â”‚   â”‚   â”œâ”€â”€ sir\_graph.yaml  
â”‚   â”‚   â”œâ”€â”€ ant\_colony.yaml  
â”‚   â”‚   â””â”€â”€ real\_dataset.yaml  
â”‚   â”‚  
â”‚   â”œâ”€â”€ baselines/  
â”‚   â”‚   â”œâ”€â”€ survival.yaml  
â”‚   â”‚   â”œâ”€â”€ state.yaml  
â”‚   â”‚   â”œâ”€â”€ heuristics.yaml  
â”‚   â”‚   â””â”€â”€ deep.yaml  
â”‚   â”‚  
â”‚   â”œâ”€â”€ experiments/  
â”‚   â”‚   â”œâ”€â”€ simulation.yaml  
â”‚   â”‚   â”œâ”€â”€ real\_data.yaml  
â”‚   â”‚   â””â”€â”€ counterfactual.yaml  
â”‚   â”‚  
â”‚   â””â”€â”€ metrics/  
â”‚       â”œâ”€â”€ lead\_time.yaml  
â”‚       â”œâ”€â”€ robustness.yaml  
â”‚       â””â”€â”€ collapse\_prob.yaml  
â”‚  
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ raw/  
â”‚   â”œâ”€â”€ processed/  
â”‚   â””â”€â”€ metrics/  
â”‚  
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ hsp/  
â”‚   â”‚   â”œâ”€â”€ \_\_init\_\_.py  
â”‚   â”‚   â”œâ”€â”€ encoding.py        \# Phase 0  
â”‚   â”‚   â”œâ”€â”€ sampling.py        \# Phase 1  
â”‚   â”‚   â”œâ”€â”€ graph.py           \# Phase 2  
â”‚   â”‚   â”œâ”€â”€ viability.py       \# Phase 3  
â”‚   â”‚   â”œâ”€â”€ optionality.py     \# Phase 4  
â”‚   â”‚   â”œâ”€â”€ collapse.py        \# Phase 5 (persistence)  
â”‚   â”‚   â”œâ”€â”€ explanation.py     \# Phase 6 (optional)  
â”‚   â”‚   â””â”€â”€ metrics.py  
â”‚   â”‚  
â”‚   â”œâ”€â”€ worlds/  
â”‚   â”‚   â”œâ”€â”€ base.py            \# BaseWorld interface  
â”‚   â”‚   â”œâ”€â”€ sir\_graph.py  
â”‚   â”‚   â”œâ”€â”€ ant\_colony.py  
â”‚   â”‚   â””â”€â”€ utils.py  
â”‚   â”‚  
â”‚   â”œâ”€â”€ baselines/  
â”‚   â”‚   â”œâ”€â”€ survival/  
â”‚   â”‚   â”œâ”€â”€ state/  
â”‚   â”‚   â”œâ”€â”€ heuristics/  
â”‚   â”‚   â””â”€â”€ deep/  
â”‚   â”‚  
â”‚   â”œâ”€â”€ experiments/  
â”‚   â”‚   â”œâ”€â”€ run\_hsp.py  
â”‚   â”‚   â”œâ”€â”€ run\_baselines.py  
â”‚   â”‚   â”œâ”€â”€ run\_counterfactuals.py  
â”‚   â”‚   â””â”€â”€ aggregate.py  
â”‚   â”‚  
â”‚   â”œâ”€â”€ utils/  
â”‚   â”‚   â”œâ”€â”€ logging.py  
â”‚   â”‚   â”œâ”€â”€ seeds.py  
â”‚   â”‚   â””â”€â”€ device.py  
â”‚   â”‚  
â”‚   â””â”€â”€ visualization/  
â”‚       â”œâ”€â”€ plots.py  
â”‚       â””â”€â”€ figures.py  
â”‚  
â”œâ”€â”€ notebooks/  
â”‚   â”œâ”€â”€ 01\_sanity.ipynb  
â”‚   â”œâ”€â”€ 02\_hsp\_vs\_baselines.ipynb  
â”‚   â””â”€â”€ 03\_paper\_figures.ipynb  
â”‚  
â””â”€â”€ results/  
    â”œâ”€â”€ simulated/  
    â”‚   â”œâ”€â”€ sir\_graph/  
    â”‚   â””â”€â”€ ant\_colony/  
    â””â”€â”€ real/

\---

DecisÃµes arquiteturais importantes (explÃ­citas)

1\. CPU-first design

torch.device("cuda" if available else "cpu")

batch pequeno

nenhum tensor gigante persistente

Patrick pode ligar GPU sem mudar cÃ³digo.

\---

2\. Hydra como espinha dorsal

Tudo configurÃ¡vel, nada hardcoded:

hsp:  
  ensemble\_size: 300  
  horizon: 50  
  delta: 0.3  
  persistence\_k: 3

Isso evita:

tuning manual

scripts Frankenstein

\---

3\. MLflow (leve, local)

SÃ³ pra:

registrar runs

salvar curvas ğ’ª\_t

logar lead time

Nada de servidor remoto.

\---

4\. DVC (opcional, mas limpo)

Usar sÃ³ para:

seeds dos mundos

mÃ©tricas finais

NÃ£o versionar gigabytes inÃºteis.

\---

Onde cada conceito mora (mapa mental)

Conceito teÃ³rico	CÃ³digo

	encoder.py  
	dynamics.py  
	sampler.py  
	survival.py  
	optionality.py  
Colapso	detector.py  
Lead time	metrics.py

Se alguÃ©m perguntar â€œonde isso vive?â€, vocÃª aponta.

\---

Como roda a PoC (1 comando)

python src/experiments/run\_hsp.py \\  
  \+world=sir\_graph \\  
  \+baseline=lstm

Depois:

python src/experiments/aggregate\_results.py

Resultado:

tabela de lead time

figuras prontas

Sem drama.

\---

PolÃ­tica clara de extensÃµes (pra nÃ£o virar caos)

âœ”ï¸ entram como mÃ³dulos opcionais

GRU

atenÃ§Ã£o

Optuna

RL

âŒ nÃ£o entram na PoC

NSSM variacional

UNet

TGN completo

SMOTE

Isso fica documentado no README. Ordem salva projeto.

Isso Ã© vini. isso Ã© sota. isso Ã© n.o.v.a.